#!/usr/bin/env python3
"""
Historical Data Update Script for Gusto Social Media Monitor
Updates the database with missing August/September 2024 data
"""

import os
import sys
import sqlite3
import logging
from datetime import datetime, timedelta
import time
import random

# Add project root to path
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(project_root)

try:
    import praw
    PRAW_AVAILABLE = True
except ImportError:
    PRAW_AVAILABLE = False
    print("WARNING: praw not available. Install with: pip install praw")

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class HistoricalDataCollector:
    """Collects historical Reddit data for missing months."""
    
    def __init__(self, db_path="gusto_monitor.db"):
        self.db_path = db_path
        
        if not PRAW_AVAILABLE:
            raise ImportError("praw required. Install with: pip install praw")
        
        # Get Reddit API credentials
        client_id = os.getenv('REDDIT_CLIENT_ID')
        client_secret = os.getenv('REDDIT_CLIENT_SECRET')
        user_agent = os.getenv('REDDIT_USER_AGENT', 'GustoSocialMonitor/1.0')
        
        if not client_id or not client_secret:
            logger.warning("‚ö†Ô∏è Reddit API credentials not found. Using demo mode.")
            self.reddit = None
        else:
            try:
                self.reddit = praw.Reddit(
                    client_id=client_id,
                    client_secret=client_secret,
                    user_agent=user_agent
                )
                logger.info("‚úÖ Reddit API connection established")
            except Exception as e:
                logger.error(f"‚ùå Failed to connect to Reddit API: {e}")
                self.reddit = None
    
    def check_missing_months(self):
        """Check what months are missing data."""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Get existing months
        cursor.execute("""
            SELECT DISTINCT strftime('%Y-%m', created_at) as month 
            FROM social_media_posts 
            ORDER BY month
        """)
        existing_months = [row[0] for row in cursor.fetchall()]
        
        logger.info(f"üìÖ Existing months in database: {existing_months}")
        
        # Check for missing months in 2024
        target_months = ['2024-08', '2024-09', '2024-10', '2024-11', '2024-12']
        missing_months = [month for month in target_months if month not in existing_months]
        
        logger.info(f"‚ùå Missing months: {missing_months}")
        conn.close()
        return missing_months
    
    def collect_historical_posts(self, target_month):
        """Collect posts for a specific month (format: YYYY-MM)."""
        if not self.reddit:
            logger.warning("‚ö†Ô∏è No Reddit API connection. Creating sample data.")
            return self._create_sample_data(target_month)
        
        year, month = target_month.split('-')
        logger.info(f"üîç Collecting posts for {target_month}")
        
        # Subreddits to search
        subreddits = [
            'smallbusiness', 'entrepreneur', 'business', 'humanresources',
            'payroll', 'accounting', 'startups', 'freelance'
        ]
        
        # Search terms
        search_terms = ['gusto payroll', 'gusto hr', 'gusto software', 'gusto review']
        
        posts_data = []
        
        for subreddit_name in subreddits:
            try:
                subreddit = self.reddit.subreddit(subreddit_name)
                logger.info(f"üìä Searching r/{subreddit_name}")
                
                # Search for posts from that time period
                for submission in subreddit.search('gusto', time_filter='all', limit=100):
                    post_date = datetime.utcfromtimestamp(submission.created_utc)
                    post_month = post_date.strftime('%Y-%m')
                    
                    if post_month == target_month:
                        full_text = f"{submission.title} {submission.selftext}".lower()
                        if 'gusto' in full_text:
                            posts_data.append({
                                'platform': 'reddit',
                                'post_id': submission.id,
                                'title': submission.title,
                                'content': submission.selftext or submission.title,
                                'author': str(submission.author) if submission.author else '[deleted]',
                                'url': f"https://reddit.com{submission.permalink}",
                                'created_at': post_date,
                                'upvotes': submission.score,
                                'comments_count': submission.num_comments,
                                'sentiment_label': 'neutral',  # Will be analyzed later
                                'sentiment_score': 0.0
                            })
                            
                            if len(posts_data) >= 20:  # Limit per month
                                break
                
                # Rate limiting
                time.sleep(random.uniform(2, 4))
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Error accessing r/{subreddit_name}: {e}")
        
        logger.info(f"‚úÖ Collected {len(posts_data)} posts for {target_month}")
        return posts_data
    
    def _create_sample_data(self, target_month):
        """Create sample data when Reddit API is not available."""
        year, month = target_month.split('-')
        
        sample_posts = []
        for i in range(5):  # Create 5 sample posts per month
            # Create dates within the target month
            day = random.randint(1, 28)
            created_at = datetime(int(year), int(month), day, 
                                random.randint(9, 17), random.randint(0, 59))
            
            sample_posts.append({
                'platform': 'reddit',
                'post_id': f'sample_{target_month}_{i}',
                'title': f'Sample Gusto discussion {i+1} for {target_month}',
                'content': f'This is sample content about Gusto for {target_month}. Discussing payroll features and user experience.',
                'author': f'sample_user_{i}',
                'url': f'https://reddit.com/r/smallbusiness/sample_{i}',
                'created_at': created_at,
                'upvotes': random.randint(1, 50),
                'comments_count': random.randint(0, 10),
                'sentiment_label': random.choice(['positive', 'neutral', 'negative']),
                'sentiment_score': random.uniform(-1.0, 1.0)
            })
        
        logger.info(f"üìù Created {len(sample_posts)} sample posts for {target_month}")
        return sample_posts
    
    def insert_posts_to_database(self, posts_data):
        """Insert posts into the database."""
        if not posts_data:
            return 0
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        inserted_count = 0
        
        for post in posts_data:
            try:
                cursor.execute("""
                    INSERT OR IGNORE INTO social_media_posts 
                    (platform, post_id, title, content, author, url, created_at, 
                     upvotes, comments_count, sentiment_label, sentiment_score)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    post['platform'], post['post_id'], post['title'], post['content'],
                    post['author'], post['url'], post['created_at'], post['upvotes'],
                    post['comments_count'], post['sentiment_label'], post['sentiment_score']
                ))
                
                if cursor.rowcount > 0:
                    inserted_count += 1
                    
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Error inserting post {post['post_id']}: {e}")
        
        conn.commit()
        conn.close()
        
        logger.info(f"‚úÖ Inserted {inserted_count} new posts into database")
        return inserted_count
    
    def update_historical_data(self):
        """Main method to update historical data."""
        logger.info("üöÄ Starting historical data update...")
        
        # Check missing months
        missing_months = self.check_missing_months()
        
        if not missing_months:
            logger.info("‚úÖ No missing months found. Database is up to date.")
            return
        
        total_inserted = 0
        
        for month in missing_months:
            logger.info(f"üìÖ Processing {month}...")
            posts = self.collect_historical_posts(month)
            inserted = self.insert_posts_to_database(posts)
            total_inserted += inserted
            
            # Delay between months
            time.sleep(2)
        
        logger.info(f"üéâ Historical data update completed! Inserted {total_inserted} total posts")
        
        # Show updated stats
        self._show_database_stats()
    
    def _show_database_stats(self):
        """Show updated database statistics."""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('SELECT COUNT(*) FROM social_media_posts')
        total = cursor.fetchone()[0]
        
        cursor.execute("""
            SELECT strftime('%Y-%m', created_at) as month, COUNT(*) 
            FROM social_media_posts 
            GROUP BY strftime('%Y-%m', created_at) 
            ORDER BY month DESC LIMIT 12
        """)
        monthly_stats = cursor.fetchall()
        
        print("\nüìä UPDATED DATABASE STATS:")
        print(f"Total posts: {total}")
        print("\nPosts by month:")
        for month, count in monthly_stats:
            print(f"  {month}: {count} posts")
        
        conn.close()

def main():
    """Main function."""
    logger.info("üéØ Historical Data Update for Gusto Social Media Monitor")
    
    try:
        collector = HistoricalDataCollector()
        collector.update_historical_data()
        
        print("\n‚úÖ Historical data update completed successfully!")
        print("üí° The database now includes data for missing months.")
        print("üîÑ You can now run the weekly refresh to keep data current.")
        
    except Exception as e:
        logger.error(f"‚ùå Error during historical data update: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())
